{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåå Inferencia Astrof√≠sica desde Ondas Gravitacionales con Modelos Surrogados\n",
    "\n",
    "Esta notebook implementa un sistema completo para generar, entrenar e inferir **par√°metros f√≠sicos** de sistemas binarios compactos (como agujeros negros o estrellas de neutrones) a partir de se√±ales de ondas gravitacionales.\n",
    "\n",
    "Utiliza modelos surrogados basados en **MLPs y CNNs** y se valida tanto con **datos sint√©ticos** como con datos reales de **GW150914 (LIGO)**.\n",
    "\n",
    "### ‚úÖ Objetivos:\n",
    "- Simular se√±ales GW con par√°metros f√≠sicos realistas.\n",
    "- Entrenar modelos surrogados para inferir esos par√°metros.\n",
    "- Validar estad√≠sticamente los modelos.\n",
    "- Aplicar inferencia directa a un evento real (GW150914).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycbc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycbc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwaveform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_td_waveform\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Carpeta de salida\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pycbc'"
     ]
    }
   ],
   "source": [
    "!pip install pycbc torch h5py pandas scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pycbc.waveform import get_td_waveform\n",
    "from scipy.signal import spectrogram\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Carpeta de salida\n",
    "output_dir = \"gw_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}/signals\", exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}/metadata\", exist_ok=True)\n",
    "\n",
    "# N√∫mero de muestras a generar\n",
    "N = 5000\n",
    "for i in tqdm(range(N), desc=\"Generando se√±ales\"):\n",
    "    m1 = np.random.uniform(20, 80)\n",
    "    m2 = np.random.uniform(10, m1)\n",
    "    spin1z = np.random.uniform(-0.99, 0.99)\n",
    "    spin2z = np.random.uniform(-0.99, 0.99)\n",
    "    distance = np.random.uniform(100, 1000)\n",
    "    redshift = np.random.uniform(0.06, 0.12)       # centrado alrededor de ~0.09\n",
    "    eccentricity = np.random.uniform(0.0, 0.05)    # la mayor√≠a de GWs tienen √≥rbitas casi circulares\n",
    "    polarization = np.random.uniform(0.0, 2*np.pi)\n",
    "    ra = np.random.uniform(0.0, 2*np.pi)\n",
    "    dec = np.random.uniform(-np.pi/2, np.pi/2)\n",
    "    tc = np.random.uniform(-0.1, 0.1)\n",
    "\n",
    "    # Clasificaci√≥n del tipo de fuente\n",
    "    if m1 < 3 and m2 < 3:\n",
    "        source_type = \"BNS\"\n",
    "    elif m1 >= 5 and m2 >= 5:\n",
    "        source_type = \"BBH\"\n",
    "    else:\n",
    "        source_type = \"BHNS\"\n",
    "\n",
    "    try:\n",
    "        hp, hc = get_td_waveform(\n",
    "            approximant=\"IMRPhenomD\",\n",
    "            mass1=m1,\n",
    "            mass2=m2,\n",
    "            spin1z=spin1z,\n",
    "            spin2z=spin2z,\n",
    "            delta_t=1.0/8192,    # üîß M√ÅS RESOLUCI√ìN\n",
    "            f_lower=10,          # üîß M√ÅS BAJA FRECUENCIA\n",
    "            distance=distance\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en muestra {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "    noise = np.random.normal(0, 1e-22, len(hp))\n",
    "    hp += noise\n",
    "\n",
    "    np.save(f\"{output_dir}/signals/hp_{i}.npy\", hp.numpy())\n",
    "    np.save(f\"{output_dir}/signals/hc_{i}.npy\", hc.numpy())\n",
    "\n",
    "    metadata = {\n",
    "        \"m1\": m1,\n",
    "        \"m2\": m2,\n",
    "        \"spin1z\": spin1z,\n",
    "        \"spin2z\": spin2z,\n",
    "        \"distance\": distance,\n",
    "        \"redshift\": redshift,\n",
    "        \"eccentricity\": eccentricity,\n",
    "        \"polarization\": polarization,\n",
    "        \"ra\": ra,\n",
    "        \"dec\": dec,\n",
    "        \"tc\": tc,\n",
    "        \"source_type\": source_type,\n",
    "        \"sample_rate\": 8192,\n",
    "        \"delta_t\": float(hp.delta_t),\n",
    "        \"f_lower\": 10,\n",
    "        \"length\": len(hp)\n",
    "    }\n",
    "\n",
    "    with open(f\"{output_dir}/metadata/params_{i}.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "# üîß Normalizaci√≥n y espectrogramas\n",
    "targets_min = np.array([5, 5, -0.99, -0.99, 100, 0.06, 0.0, 0.0, 0.0, -np.pi/2, -0.1])\n",
    "targets_max = np.array([80, 80, 0.99, 0.99, 1000, 0.12, 0.05, 2*np.pi, 2*np.pi, np.pi/2, 0.1])\n",
    "\n",
    "X_list, y_list, class_list = [], [], []\n",
    "signal_dir = \"gw_dataset/signals\"\n",
    "meta_dir = \"gw_dataset/metadata\"\n",
    "source_type_map = {\"BBH\": 0, \"BNS\": 1, \"BHNS\": 2}\n",
    "\n",
    "valid_count = 0\n",
    "for i in tqdm(range(N), desc=\"Procesando espectrogramas\"):\n",
    "    try:\n",
    "        signal_path = os.path.join(signal_dir, f\"hp_{i}.npy\")\n",
    "        meta_path = os.path.join(meta_dir, f\"params_{i}.json\")\n",
    "\n",
    "        hp = np.load(signal_path)\n",
    "        with open(meta_path, \"r\") as f:\n",
    "            meta = json.load(f)\n",
    "\n",
    "        f_, t_, Sxx = spectrogram(hp, fs=8192, nperseg=128)\n",
    "        Sxx = np.log10(Sxx + 1e-10)\n",
    "\n",
    "        # üîß Ajustar tama√±o exacto 64x64 con padding si es necesario\n",
    "        Sxx = Sxx[:64, :64]\n",
    "        pad_h = 64 - Sxx.shape[0]\n",
    "        pad_w = 64 - Sxx.shape[1]\n",
    "        Sxx = np.pad(Sxx, ((0, pad_h), (0, pad_w)), mode='constant', constant_values=0)\n",
    "\n",
    "        X_list.append(Sxx)\n",
    "        valid_count += 1\n",
    "\n",
    "        targets = np.array([\n",
    "            meta[\"m1\"], meta[\"m2\"], meta[\"spin1z\"], meta[\"spin2z\"],\n",
    "            meta[\"distance\"], meta[\"redshift\"], meta[\"eccentricity\"],\n",
    "            meta[\"polarization\"], meta[\"ra\"], meta[\"dec\"], meta[\"tc\"]\n",
    "        ])\n",
    "        targets_norm = (targets - targets_min) / (targets_max - targets_min)\n",
    "        y_list.append(targets_norm)\n",
    "        class_list.append(source_type_map[meta[\"source_type\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en muestra {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"‚úÖ Se√±ales v√°lidas generadas: {valid_count}/{N}\")\n",
    "\n",
    "# Convertir a tensores\n",
    "X = torch.tensor(np.stack(X_list)).unsqueeze(1).float()\n",
    "y = torch.tensor(np.stack(y_list)).float()\n",
    "labels = torch.tensor(class_list).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SurrogateCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SurrogateCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n",
    "        self.fc_reg = nn.Linear(256, 11)\n",
    "        self.fc_cls = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out_reg = self.fc_reg(x)\n",
    "        out_cls = F.log_softmax(self.fc_cls(x), dim=1)  # ‚úÖ log_softmax\n",
    "        return out_reg, out_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "model = SurrogateCNN()\n",
    "dataset = TensorDataset(X, y, labels)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_reg = nn.MSELoss()\n",
    "loss_cls = nn.NLLLoss()\n",
    "\n",
    "alpha = 1.0\n",
    "beta = 0.1\n",
    "\n",
    "prev_loss = None\n",
    "patience_counter = 0\n",
    "patience_limit = 5\n",
    "tolerance = 0.01\n",
    "max_epochs = 10  # por si tarda mucho\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb, lb in loader:\n",
    "        pred_reg, pred_cls = model(xb)\n",
    "        loss = alpha * loss_reg(pred_reg, yb) + beta * loss_cls(pred_cls, lb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Total Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Comprobaci√≥n de convergencia\n",
    "    if prev_loss is not None and abs(total_loss - prev_loss) < tolerance:\n",
    "        patience_counter += 1\n",
    "    else:\n",
    "        patience_counter = 0\n",
    "\n",
    "    if patience_counter >= patience_limit:\n",
    "        print(f\"‚úÖ Convergencia alcanzada en la √©poca {epoch+1}. Deteniendo entrenamiento.\")\n",
    "        break\n",
    "\n",
    "    prev_loss = total_loss\n",
    "\n",
    "# Guardar modelo final\n",
    "torch.save(model.state_dict(), \"modelo_surrogado_weights.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SurrogateCNN()\n",
    "model.load_state_dict(torch.load(\"modelo_surrogado_weights.pt\", map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_reg, pred_cls = model(X[0:1])\n",
    "    pred_reg = pred_reg.numpy()[0]\n",
    "    pred_cls = pred_cls.argmax(dim=1).item()\n",
    "\n",
    "    # Desnormalizaci√≥n\n",
    "    pred_reg = pred_reg * (targets_max - targets_min) + targets_min\n",
    "\n",
    "    # Validaci√≥n f√≠sica\n",
    "    pred_reg[6] = np.clip(pred_reg[6], 0, 1)  # excentricidad\n",
    "    pred_reg[9] = np.clip(pred_reg[9], -np.pi/2, np.pi/2)  # declinaci√≥n\n",
    "    pred_reg[10] = np.clip(pred_reg[10], -0.1, 0.1)  # tc\n",
    "\n",
    "    print(\"Predicci√≥n f√≠sica:\")\n",
    "    for name, val in zip([\n",
    "        \"m1\", \"m2\", \"spin1z\", \"spin2z\", \"distance\", \"redshift\",\n",
    "        \"eccentricity\", \"polarization\", \"ra\", \"dec\", \"tc\"\n",
    "    ], pred_reg):\n",
    "        print(f\"{name}: {val:.4f}\")\n",
    "\n",
    "    tipo_fuente = [\"BBH\", \"BNS\", \"BHNS\"][pred_cls]\n",
    "    print(\"Tipo de fuente predicho:\", tipo_fuente)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE medio (regresi√≥n): 86234352.000\n",
      "Accuracy tipo de sistema: 0.200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BNS       0.00      0.00      0.00        10\n",
      "        BHNS       0.00      0.00      0.00         6\n",
      "         BBH       0.20      1.00      0.33         4\n",
      "\n",
      "    accuracy                           0.20        20\n",
      "   macro avg       0.07      0.33      0.11        20\n",
      "weighted avg       0.04      0.20      0.07        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oscar\\Desktop\\TfmAstro\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\oscar\\Desktop\\TfmAstro\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\oscar\\Desktop\\TfmAstro\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ID de la muestra sobre la que hiciste la predicci√≥n\n",
    "sample_id = 0\n",
    "\n",
    "# Cargar valores reales desde el JSON correspondiente\n",
    "with open(f\"gw_dataset/metadata/params_{sample_id}.json\") as f:\n",
    "    valores_reales = json.load(f)\n",
    "\n",
    "# Emparejar campos relevantes\n",
    "campos = [\"m1\", \"m2\", \"spin1z\", \"spin2z\", \"distance\", \"redshift\", \"eccentricity\", \"polarization\", \"ra\", \"dec\", \"tc\"]\n",
    "valores_reales_vec = np.array([valores_reales[c] for c in campos])\n",
    "\n",
    "# Calcular errores\n",
    "errores_abs = np.abs(pred_reg - valores_reales_vec)\n",
    "errores_rel = errores_abs / (np.abs(valores_reales_vec) + 1e-8)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\nüìä Comparaci√≥n modelo vs. real:\")\n",
    "print(f\"{'Par√°metro':<15} {'Predicho':>10} {'Real':>10} {'Error abs.':>12} {'Error rel.':>12}\")\n",
    "for i, nombre in enumerate(campos):\n",
    "    print(f\"{nombre:<15} {pred_reg[i]:10.4f} {valores_reales_vec[i]:10.4f} {errores_abs[i]:12.4f} {errores_rel[i]*100:11.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
